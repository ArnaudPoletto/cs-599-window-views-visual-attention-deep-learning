{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DPTForDepthEstimation\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "from src.config import PROCESSED_SALICON_PATH\n",
    "from src.datasets.salicon_dataset import SaliconDataset\n",
    "from src.utils.file import get_paths_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n",
      "torch.Size([1, 768, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForDepthEstimation \n",
    "\n",
    "model_name = \"depth-anything/Depth-Anything-V2-Base-hf\"\n",
    "base_model = AutoModelForDepthEstimation.from_pretrained(model_name, output_hidden_states=True)\n",
    "base_model.eval()\n",
    "base_model.to(\"cuda\")\n",
    "input = torch.randn(1, 3, 224, 224).to(\"cuda\")\n",
    "output = base_model(input)\n",
    "hidden_states = output.hidden_states\n",
    "feature_maps = []\n",
    "for hidden_state in hidden_states:\n",
    "    patch_embeddings = hidden_state[:, 1:, :]\n",
    "    size = int(np.sqrt(patch_embeddings.shape[1]))\n",
    "    feature_map = patch_embeddings.reshape(1, size, size, -1).permute(0, 3, 1, 2)\n",
    "    feature_maps.append(feature_map)\n",
    "    print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DepthEstimatorOutput(loss=None, predicted_depth=tensor([[[3.6459, 3.6371, 3.6382,  ..., 3.8307, 3.8642, 3.4359],\n",
       "         [3.5851, 3.5965, 3.6461,  ..., 3.8302, 3.8002, 3.8375],\n",
       "         [3.6379, 3.6354, 3.6346,  ..., 3.8314, 3.8384, 3.8129],\n",
       "         ...,\n",
       "         [3.7470, 3.7505, 3.7726,  ..., 3.4320, 3.4412, 3.4475],\n",
       "         [3.7737, 3.7316, 3.7884,  ..., 3.4462, 3.4444, 3.4539],\n",
       "         [3.8146, 3.7688, 3.7746,  ..., 3.4340, 3.4360, 3.4613]]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>), hidden_states=(tensor([[[-0.0021, -0.0014, -0.0921,  ...,  0.0141,  0.0094,  0.0022],\n",
       "         [-0.4140,  0.0083, -0.1673,  ...,  0.0166,  0.1997, -0.2020],\n",
       "         [-0.0549, -0.0288, -0.1283,  ...,  0.2133, -0.2188,  0.1699],\n",
       "         ...,\n",
       "         [ 0.2361,  0.0428, -0.0536,  ..., -0.0881,  0.1829, -0.1304],\n",
       "         [ 0.2749, -0.0476,  0.0102,  ...,  0.3193, -0.1028,  0.3406],\n",
       "         [-0.0956,  0.0676,  0.0994,  ...,  0.0054,  0.0290,  0.3170]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 0.0102, -0.0552, -0.0942,  ...,  0.0002,  0.0033,  0.0103],\n",
       "         [-0.1348,  0.0805, -0.0839,  ...,  0.0306,  0.1376, -0.1405],\n",
       "         [-0.0662,  0.0225, -0.1023,  ...,  0.1709, -0.0941,  0.0638],\n",
       "         ...,\n",
       "         [ 0.1817, -0.0232,  0.0185,  ..., -0.0158,  0.1732, -0.1204],\n",
       "         [ 0.2057, -0.0181,  0.0585,  ...,  0.1985, -0.0847,  0.1062],\n",
       "         [ 0.1214, -0.0928,  0.1056,  ...,  0.0055,  0.0486,  0.2046]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-0.0103, -0.1080, -0.0247,  ..., -0.0029,  0.0014, -0.0009],\n",
       "         [-0.0283,  0.1011, -0.0590,  ...,  0.0805,  0.1159, -0.0594],\n",
       "         [-0.0234,  0.0008, -0.1021,  ...,  0.1324, -0.0289,  0.0391],\n",
       "         ...,\n",
       "         [ 0.0453,  0.0407,  0.0346,  ...,  0.0075,  0.0880, -0.0298],\n",
       "         [ 0.1244,  0.0148,  0.0266,  ...,  0.1731, -0.1366, -0.0341],\n",
       "         [ 0.0700,  0.0112,  0.0880,  ...,  0.0334,  0.0806,  0.1592]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-1.4056e-02, -1.8551e-01, -1.3895e-05,  ..., -3.1411e-02,\n",
       "          -1.8788e-02, -1.4833e-02],\n",
       "         [ 3.3019e-02,  6.2388e-02, -7.1577e-02,  ...,  7.0301e-02,\n",
       "          -9.6680e-03, -1.0294e-03],\n",
       "         [ 3.7744e-02, -1.6532e-02, -1.6649e-01,  ...,  8.0050e-02,\n",
       "          -3.7067e-02,  4.2871e-02],\n",
       "         ...,\n",
       "         [ 2.7727e-02,  7.5121e-03,  3.9848e-04,  ...,  1.4739e-02,\n",
       "          -2.0316e-02, -1.2101e-02],\n",
       "         [ 3.4775e-02,  8.6684e-03, -1.2529e-03,  ...,  7.0856e-02,\n",
       "          -1.3473e-01, -3.6267e-02],\n",
       "         [ 8.3663e-03, -2.3382e-02,  3.5538e-02,  ..., -2.3456e-02,\n",
       "          -6.5100e-03,  1.9708e-02]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-0.0196, -0.1994,  0.0590,  ..., -0.0079,  0.0386,  0.0272],\n",
       "         [ 0.0426,  0.1398, -0.0154,  ...,  0.0628,  0.0218,  0.0110],\n",
       "         [ 0.0966,  0.0522, -0.1189,  ...,  0.0465, -0.0436,  0.0226],\n",
       "         ...,\n",
       "         [ 0.1366,  0.0312,  0.0899,  ...,  0.0569,  0.0362, -0.0121],\n",
       "         [ 0.0474,  0.1187,  0.0782,  ...,  0.0274, -0.1039, -0.0477],\n",
       "         [ 0.0715, -0.0068,  0.1134,  ..., -0.0181, -0.0695, -0.0133]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-0.0320, -0.1901,  0.0813,  ..., -0.0698,  0.0521,  0.0565],\n",
       "         [-0.0057,  0.0515, -0.0523,  ...,  0.0671,  0.0494,  0.0439],\n",
       "         [ 0.0101,  0.0593, -0.0942,  ...,  0.0881, -0.0073,  0.0143],\n",
       "         ...,\n",
       "         [ 0.1049,  0.0288,  0.1072,  ...,  0.0465,  0.0348, -0.0094],\n",
       "         [-0.0418,  0.0855,  0.0148,  ...,  0.0467, -0.0776, -0.0667],\n",
       "         [ 0.0335, -0.0169,  0.1495,  ...,  0.0288, -0.0404, -0.0140]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-2.8757e-02, -1.2858e-01,  1.5894e-01,  ..., -1.2159e-02,\n",
       "          -1.3575e-02,  4.1099e-02],\n",
       "         [-7.4769e-02,  1.7098e-01, -1.5644e-01,  ...,  8.8892e-02,\n",
       "          -6.3080e-02,  1.0933e-01],\n",
       "         [ 2.9327e-02,  9.0673e-02, -1.1487e-01,  ...,  6.2696e-02,\n",
       "          -1.0800e-01,  1.5448e-02],\n",
       "         ...,\n",
       "         [ 8.3736e-02,  1.0740e-01,  7.5999e-02,  ...,  5.2294e-02,\n",
       "          -2.2009e-02, -3.3467e-05],\n",
       "         [ 2.2524e-02,  6.9948e-02, -1.1990e-02,  ...,  5.5056e-02,\n",
       "          -1.1610e-01, -4.7687e-02],\n",
       "         [ 9.8580e-02, -2.8724e-02,  1.5665e-01,  ...,  2.2146e-02,\n",
       "          -1.0537e-01, -6.8990e-03]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[-0.0828, -0.1607,  0.0991,  ..., -0.0520, -0.0450, -0.0668],\n",
       "         [-0.0372,  0.2469, -0.2638,  ..., -0.0065,  0.0581,  0.0530],\n",
       "         [ 0.0098,  0.0321, -0.3171,  ...,  0.0208, -0.0182, -0.0944],\n",
       "         ...,\n",
       "         [ 0.1174,  0.1336, -0.0749,  ...,  0.1901,  0.0407, -0.0918],\n",
       "         [ 0.0874,  0.0248, -0.2890,  ...,  0.2471, -0.0297, -0.0896],\n",
       "         [ 0.2094, -0.1406,  0.0466,  ...,  0.1969, -0.0040, -0.1018]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 0.0636,  0.0197,  0.0601,  ..., -0.0500,  0.0408, -0.0781],\n",
       "         [ 0.2898,  0.5381, -0.0682,  ..., -0.2452,  0.2864, -0.0065],\n",
       "         [ 0.0077,  0.1690, -0.2553,  ...,  0.0562,  0.1530,  0.1399],\n",
       "         ...,\n",
       "         [ 0.4086,  0.2313,  0.1551,  ...,  0.1432,  0.1375,  0.0011],\n",
       "         [ 0.3818,  0.2889, -0.1993,  ...,  0.1003, -0.0163,  0.0926],\n",
       "         [ 0.4965, -0.0477,  0.1802,  ...,  0.0883,  0.1451, -0.0114]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 0.1731,  0.0676, -0.0941,  ...,  0.1897, -0.0135, -0.0159],\n",
       "         [ 2.2128,  4.3415,  5.0517,  ...,  1.7027, -4.0568, -1.8688],\n",
       "         [ 0.0184,  0.4786, -0.6512,  ..., -0.0638,  0.4348, -0.0470],\n",
       "         ...,\n",
       "         [ 0.8335,  0.3914,  0.1804,  ..., -0.1700,  0.3131, -0.1039],\n",
       "         [ 0.6421,  0.4714, -0.4388,  ..., -0.2018,  0.2009,  0.0250],\n",
       "         [ 0.7905,  0.2432,  0.1107,  ..., -0.2238,  0.2158, -0.2163]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.0657e+00, -9.2229e-01, -2.4916e-01,  ...,  3.0186e-01,\n",
       "           3.5567e-03, -1.3661e-02],\n",
       "         [ 1.7870e+00,  3.9637e+00,  5.5323e+00,  ...,  1.6286e+00,\n",
       "          -4.1965e+00, -1.3002e+00],\n",
       "         [ 6.4868e-01, -5.4382e-01, -1.1872e+00,  ..., -5.0782e-01,\n",
       "           1.0653e-01,  2.4679e-01],\n",
       "         ...,\n",
       "         [ 1.5393e+00, -5.8303e-01, -5.8276e-01,  ...,  9.8579e-02,\n",
       "           7.1049e-01, -9.8480e-02],\n",
       "         [ 1.5107e+00, -3.6128e-01, -1.7048e+00,  ..., -1.6696e-02,\n",
       "           9.2955e-02,  3.8087e-01],\n",
       "         [ 1.5028e+00, -7.2681e-01, -6.8426e-01,  ..., -3.5531e-01,\n",
       "           1.9765e-01, -9.1738e-02]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 2.2510, -0.4239,  0.5063,  ...,  0.2572, -0.9869,  0.0633],\n",
       "         [ 3.0439,  3.8411,  6.2384,  ...,  1.1188, -4.7326, -0.4828],\n",
       "         [ 1.2585, -0.7212, -2.1230,  ..., -0.6776,  0.4203, -0.5592],\n",
       "         ...,\n",
       "         [ 2.8009, -1.2579, -0.4538,  ..., -0.4251,  0.2668, -0.1716],\n",
       "         [ 2.2480, -0.1631, -2.3854,  ..., -0.2305,  0.6196,  0.3920],\n",
       "         [ 3.2943, -1.6521, -1.0815,  ..., -1.2634,  0.3184, -0.5894]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.6863, -1.1859, -0.1135,  ..., -0.5543, -1.5786, -1.6392],\n",
       "         [-0.3602, -1.2952,  0.1948,  ..., -1.7257, -1.1781, -3.1229],\n",
       "         [ 1.6556, -2.9024, -3.3596,  ..., -1.5555, -0.5161, -1.7706],\n",
       "         ...,\n",
       "         [ 4.1188, -2.1306, -2.4676,  ..., -1.2429, -0.9296, -1.8253],\n",
       "         [ 2.8993, -1.1719, -4.6293,  ..., -0.5080, -0.4753, -1.3141],\n",
       "         [ 5.0322, -3.4149, -3.0053,  ..., -2.2015, -0.7732, -2.2211]]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)), attentions=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['predicted_depth', 'hidden_states'])\n",
      "torch.Size([1, 224, 224])\n",
      "[torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768]), torch.Size([1, 257, 768])]\n"
     ]
    }
   ],
   "source": [
    "print(output.keys())\n",
    "print(output[\"predicted_depth\"].shape)\n",
    "print([x.shape for x in output[\"hidden_states\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DepthAnythingForDepthEstimation.forward() got an unexpected keyword argument 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m DepthModelWithFeatures(model_name\u001b[38;5;241m=\u001b[39mmodel_name)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m hidden_features, predicted_depth \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m([x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m hidden_features])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(predicted_depth\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\pdm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\pdm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m, in \u001b[0;36mDepthModelWithFeatures.forward\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):         \n\u001b[1;32m---> 11\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m          \n\u001b[0;32m     12\u001b[0m     hidden_features \u001b[38;5;241m=\u001b[39m encoder_outputs\u001b[38;5;241m.\u001b[39mhidden_states  \n\u001b[0;32m     13\u001b[0m     predicted_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mpredicted_depth  \n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\pdm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arnau\\anaconda3\\envs\\pdm\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: DepthAnythingForDepthEstimation.forward() got an unexpected keyword argument 'input'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForDepthEstimation \n",
    "import torch.nn as nn\n",
    "import torch  \n",
    "\n",
    "class DepthModelWithFeatures(nn.Module):     \n",
    "    def __init__(self, model_name):         \n",
    "        super().__init__()         \n",
    "        self.base_model = AutoModelForDepthEstimation.from_pretrained(model_name)      \n",
    "\n",
    "    def forward(self, **kwargs):         \n",
    "        encoder_outputs = self.base_model(**kwargs)          \n",
    "        hidden_features = encoder_outputs.hidden_states  \n",
    "        predicted_depth = self.base_model(**kwargs).predicted_depth  \n",
    "\n",
    "        return hidden_features, predicted_depth \n",
    "        \n",
    "model_name = \"depth-anything/Depth-Anything-V2-Base-hf\"\n",
    "model = DepthModelWithFeatures(model_name=model_name)\n",
    "input = torch.rand(1, 3, 224, 224)\n",
    "hidden_features, predicted_depth = model(input)\n",
    "print([x.shape for x in hidden_features])\n",
    "print(predicted_depth.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\arnau/.cache\\torch\\hub\\intel-isl_MiDaS_master\n",
      "c:\\Users\\arnau\\anaconda3\\envs\\pdm\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\arnau/.cache\\torch\\hub\\rwightman_gen-efficientnet-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "#model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
    "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
    "model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1, 3, 224, 224)\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_depth torch.Size([1, 224, 224])\n",
      "hidden_states [torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024]), torch.Size([1, 197, 1024])]\n"
     ]
    }
   ],
   "source": [
    "output.keys()\n",
    "print(\"predicted_depth\", output[\"predicted_depth\"].shape)\n",
    "print(\"hidden_states\", [hs.shape for hs in output[\"hidden_states\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
